{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UlUVJMdLTWi9"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "GSoRhGCN7lEu"
   },
   "outputs": [],
   "source": [
    "# configs\n",
    "# environment: gcolab - Google Colab, local - local machine\n",
    "environment = 'local'\n",
    "#environment= 'gcolab'\n",
    "# debug mode: if it is set True, only use partial dataset for the purpose of debug or demonstration\n",
    "debug_mode = True\n",
    "# load_existing_w_matrix: it it is set True, the previous built similarity matrix will be loaded instead of building one\n",
    "load_existing_w_matrix = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the file path where the similarity matrix will be persisted\n",
    "if debug_mode == True:\n",
    "    DEFAULT_PARTICLE_PATH = 'w_matrix_debug.pkl'\n",
    "else:\n",
    "    DEFAULT_PARTICLE_PATH = 'w_matrix.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 152,
     "output_extras": [
      {
       "item_id": 4
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "gZxLRoWgguMq",
    "outputId": "ab5e77d0-e42b-415f-e489-f200357e10cb"
   },
   "outputs": [],
   "source": [
    "# install libraries and authorise google drive\n",
    "if environment == 'gcolab':\n",
    "    get_ipython().system('apt-get install -y -qq software-properties-common python-software-properties module-init-tools')\n",
    "    get_ipython().system('add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null')\n",
    "    get_ipython().system('apt-get update -qq 2>&1 > /dev/null')\n",
    "    get_ipython().system('apt-get -y install -qq google-drive-ocamlfuse fuse')\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "    creds = GoogleCredentials.get_application_default()\n",
    "    import getpass\n",
    "    get_ipython().system('google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL')\n",
    "    vcode = getpass.getpass()\n",
    "    get_ipython().system('echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "EUAsBiE_hwMC"
   },
   "outputs": [],
   "source": [
    "# mount google drive\n",
    "if environment == 'gcolab': \n",
    "    get_ipython().system('mkdir -p drive')\n",
    "    get_ipython().system('google-drive-ocamlfuse drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "cRlDKbkrf59j"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "if environment == 'gcolab':\n",
    "    ratings = pd.read_csv(\"drive/Colab-Notebooks/datasets/ratings.csv\", encoding='\"ISO-8859-1\"')\n",
    "    movies = pd.read_csv(\"drive/Colab-Notebooks/datasets/movies.csv\", encoding='\"ISO-8859-1\"')\n",
    "    tags = pd.read_csv(\"drive/Colab-Notebooks/datasets/tags.csv\", encoding='\"ISO-8859-1\"')\n",
    "    DEFAULT_PARTICLE_PATH = \"drive/Colab-Notebooks/\" + DEFAULT_PARTICLE_PATH\n",
    "else:\n",
    "    ratings = pd.read_csv(\"datasets/ratings.csv\", encoding='\"ISO-8859-1\"')\n",
    "    movies = pd.read_csv(\"datasets/movies.csv\", encoding='\"ISO-8859-1\"')\n",
    "    tags = pd.read_csv(\"datasets/tags.csv\", encoding='\"ISO-8859-1\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use partial dataset for debug mode\n",
    "if debug_mode == True:\n",
    "    ratings = ratings[(ratings['movieId'] < 100) & (ratings['userId'] < 100)]\n",
    "    movies = movies[movies['movieId'] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 585,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 3
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 702,
     "status": "ok",
     "timestamp": 1522179608230,
     "user": {
      "displayName": "王斌",
      "photoUrl": "//lh4.googleusercontent.com/-9f8d4yYgX28/AAAAAAAAAAI/AAAAAAAAACA/HwJCudpagNI/s50-c-k-no/photo.jpg",
      "userId": "115452681032561910662"
     },
     "user_tz": -780
    },
    "id": "GH60Zmd46lvq",
    "outputId": "cc36501c-e9c0-446a-f229-9581781f6614"
   },
   "outputs": [],
   "source": [
    "# split the ratings into training and test\n",
    "ratings_training = ratings.sample(frac=0.7)\n",
    "ratings_test = ratings.drop(ratings_training.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate adjusted ratings based on training data\n",
    "rating_mean= ratings_training.groupby(['movieId'], as_index = False, sort = False).mean().rename(columns = {'rating': 'rating_mean'})[['movieId','rating_mean']]\n",
    "adjusted_ratings = pd.merge(ratings_training,rating_mean,on = 'movieId', how = 'left', sort = False)\n",
    "adjusted_ratings['rating_adjusted']=adjusted_ratings['rating']-adjusted_ratings['rating_mean']\n",
    "# replace 0 adjusted rating values to 1*e-8 in order to avoid 0 denominator\n",
    "adjusted_ratings.loc[adjusted_ratings['rating_adjusted'] == 0, 'rating_adjusted'] = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 206,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 723,
     "status": "ok",
     "timestamp": 1522179689297,
     "user": {
      "displayName": "王斌",
      "photoUrl": "//lh4.googleusercontent.com/-9f8d4yYgX28/AAAAAAAAAAI/AAAAAAAAACA/HwJCudpagNI/s50-c-k-no/photo.jpg",
      "userId": "115452681032561910662"
     },
     "user_tz": -780
    },
    "id": "4rIbk-wC8apw",
    "outputId": "b5fb6f9a-579b-4e4d-9857-6d1bbd7e8817"
   },
   "outputs": [],
   "source": [
    "# function of building the item-to-item weight matrix\n",
    "def build_w_matrix(adjusted_ratings, load_existing_w_matrix):\n",
    "    # define weight matrix\n",
    "    w_matrix_columns = ['movie_1', 'movie_2', 'weight']\n",
    "    w_matrix=pd.DataFrame(columns=w_matrix_columns)\n",
    "\n",
    "    # load weight matrix from pickle file\n",
    "    if load_existing_w_matrix:\n",
    "        with open(DEFAULT_PARTICLE_PATH, 'rb') as input:\n",
    "            w_matrix = pickle.load(input)\n",
    "        input.close()\n",
    "\n",
    "    # calculate the similarity values\n",
    "    else:\n",
    "        distinct_movies = np.unique(adjusted_ratings['movieId'])\n",
    "\n",
    "        i = 0\n",
    "        # for each movie_1 in all movies\n",
    "        for movie_1 in distinct_movies:\n",
    "\n",
    "            if i%10==0:\n",
    "                print(i , \"out of \", len(distinct_movies))\n",
    "\n",
    "            # extract all users who rated movie_1\n",
    "            user_data = adjusted_ratings[adjusted_ratings['movieId'] == movie_1]\n",
    "            distinct_users = np.unique(user_data['userId'])\n",
    "\n",
    "            # record the ratings for users who rated both movie_1 and movie_2\n",
    "            record_row_columns = ['userId', 'movie_1', 'movie_2', 'rating_adjusted_1', 'rating_adjusted_2']\n",
    "            record_movie_1_2 = pd.DataFrame(columns=record_row_columns)\n",
    "            # for each customer C who rated movie_1\n",
    "            for c_userid in distinct_users:\n",
    "                print('build weight matrix for customer %d, movie_1 %d' % (c_userid, movie_1))\n",
    "                # the customer's rating for movie_1\n",
    "                c_movie_1_rating = user_data[user_data['userId'] == c_userid]['rating_adjusted'].iloc[0]\n",
    "                # extract movies rated by the customer excluding movie_1\n",
    "                c_user_data = adjusted_ratings[(adjusted_ratings['userId'] == c_userid) & (adjusted_ratings['movieId'] != movie_1)]\n",
    "                c_distinct_movies = np.unique(c_user_data['movieId'])\n",
    "\n",
    "                # for each movie rated by customer C as movie=2\n",
    "                for movie_2 in c_distinct_movies:\n",
    "                    # the customer's rating for movie_2\n",
    "                    c_movie_2_rating = c_user_data[c_user_data['movieId'] == movie_2]['rating_adjusted'].iloc[0]\n",
    "                    record_row = pd.Series([c_userid, movie_1, movie_2, c_movie_1_rating, c_movie_2_rating], index=record_row_columns)\n",
    "                    record_movie_1_2 = record_movie_1_2.append(record_row, ignore_index=True)\n",
    "\n",
    "            # calculate the similarity values between movie_1 and the above recorded movies\n",
    "            distinct_movie_2 = np.unique(record_movie_1_2['movie_2'])\n",
    "            # for each movie 2\n",
    "            for movie_2 in distinct_movie_2:\n",
    "                print('calculate weight movie_1 %d, movie_2 %d' % (movie_1, movie_2))\n",
    "                paired_movie_1_2 = record_movie_1_2[record_movie_1_2['movie_2'] == movie_2]\n",
    "                sim_value_numerator = (paired_movie_1_2['rating_adjusted_1'] * paired_movie_1_2['rating_adjusted_2']).sum()\n",
    "                sim_value_denominator = np.sqrt(np.square(paired_movie_1_2['rating_adjusted_1']).sum()) * np.sqrt(np.square(paired_movie_1_2['rating_adjusted_2']).sum())\n",
    "                sim_value_denominator = sim_value_denominator if sim_value_denominator != 0 else 1e-8\n",
    "                sim_value = sim_value_numerator / sim_value_denominator\n",
    "                w_matrix = w_matrix.append(pd.Series([movie_1, movie_2, sim_value], index=w_matrix_columns), ignore_index=True)\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "        # output weight matrix to pickle file\n",
    "        with open(DEFAULT_PARTICLE_PATH, 'wb') as output:\n",
    "            pickle.dump(w_matrix, output, pickle.HIGHEST_PROTOCOL)\n",
    "        output.close()\n",
    "\n",
    "    return w_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 384,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24107,
     "status": "error",
     "timestamp": 1522195360525,
     "user": {
      "displayName": "王斌",
      "photoUrl": "//lh4.googleusercontent.com/-9f8d4yYgX28/AAAAAAAAAAI/AAAAAAAAACA/HwJCudpagNI/s50-c-k-no/photo.jpg",
      "userId": "115452681032561910662"
     },
     "user_tz": -780
    },
    "id": "lgfCfmc8-J1B",
    "outputId": "da2feece-8bb5-46a7-b198-553502819ead"
   },
   "outputs": [],
   "source": [
    "# run the function to build similarity matrix\n",
    "w_matrix = build_w_matrix(adjusted_ratings, load_existing_w_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eCcsE8W9L1UI"
   },
   "outputs": [],
   "source": [
    "# calculate the predicted ratings\n",
    "def predict(userId, movieId, w_matrix, adjusted_ratings, rating_mean):\n",
    "    # fix missing mean rating which was caused by no ratings for the given movie\n",
    "    # mean_rating exists for movieId\n",
    "    if rating_mean[rating_mean['movieId'] == movieId].shape[0] > 0:\n",
    "        mean_rating = rating_mean[rating_mean['movieId'] == movieId]['rating_mean'].iloc[0]\n",
    "    # mean_rating does not exist for movieId(which may be caused by no ratings for the movie)\n",
    "    else:\n",
    "        mean_rating = 2.5\n",
    "\n",
    "    # calculate the rating of the given movie by the given user\n",
    "    user_other_ratings = adjusted_ratings[adjusted_ratings['userId'] == userId]\n",
    "    user_distinct_movies = np.unique(user_other_ratings['movieId'])\n",
    "    sum_weighted_other_ratings = 0\n",
    "    sum_weghts = 0\n",
    "    for movie_j in user_distinct_movies:\n",
    "        if rating_mean[rating_mean['movieId'] == movie_j].shape[0] > 0:\n",
    "            rating_mean_j = rating_mean[rating_mean['movieId'] == movie_j]['rating_mean'].iloc[0]\n",
    "        else:\n",
    "            rating_mean_j = 2.5\n",
    "        # only calculate the weighted values when the weight between movie_1 and movie_2 exists in weight matrix\n",
    "        w_movie_1_2 = w_matrix[(w_matrix['movie_1'] == movieId) & (w_matrix['movie_2'] == movie_j)]\n",
    "        if w_movie_1_2.shape[0] > 0:\n",
    "            user_rating_j = user_other_ratings[user_other_ratings['movieId']==movie_j]\n",
    "            sum_weighted_other_ratings += (user_rating_j['rating'].iloc[0] - rating_mean_j) * w_movie_1_2['weight'].iloc[0]\n",
    "            sum_weghts += np.abs(w_movie_1_2['weight'].iloc[0])\n",
    "\n",
    "    # if sum_weights is 0 (which may be because of no ratings from new users), use the mean ratings\n",
    "    if sum_weghts == 0:\n",
    "        predicted_rating = mean_rating\n",
    "    # sum_weights is bigger than 0\n",
    "    else:\n",
    "        predicted_rating = mean_rating + sum_weighted_other_ratings/sum_weghts\n",
    "\n",
    "    return predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted rating: 4.010888\n"
     ]
    }
   ],
   "source": [
    "# predict a rating for a given user and given movie\n",
    "predicted_rating = predict(2, 29, w_matrix, adjusted_ratings, rating_mean)\n",
    "print('The predicted rating: %f' % predicted_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the learned recommender system on test data by converting the ratings to negative and positive\n",
    "def binary_eval(ratings_test, w_matrix, adjusted_ratings, rating_mean):\n",
    "    # predict all the ratings for test data\n",
    "    ratings_test = ratings_test.assign(predicted_rating = pd.Series(np.zeros(ratings_test.shape[0])))\n",
    "    for index, row_rating in ratings_test.iterrows():\n",
    "        predicted_rating = predict(row_rating['userId'], row_rating['movieId'], w_matrix, adjusted_ratings, rating_mean)\n",
    "        ratings_test.loc[index, 'predicted_rating'] = predicted_rating\n",
    "    tp = ratings_test.query('(rating >= 2.5) & (predicted_rating >= 2.5)').shape[0]\n",
    "    fp = ratings_test.query('(rating < 2.5) & (predicted_rating >= 2.5)').shape[0]\n",
    "    fn = ratings_test.query('(rating >= 2.5) & (predicted_rating < 2.5)').shape[0]\n",
    "\n",
    "    # calculate the precision and recall\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    return (precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result - precision: 0.929032, recall: 0.923077\n"
     ]
    }
   ],
   "source": [
    "# run the evaluation\n",
    "eval_result = binary_eval(ratings_test, w_matrix, adjusted_ratings, rating_mean)\n",
    "print('Evaluation result - precision: %f, recall: %f' % eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make recommendations\n",
    "def recommend(userID, w_matrix, adjusted_ratings, rating_mean, amount=10):\n",
    "    distinct_movies = np.unique(adjusted_ratings['movieId'])\n",
    "    user_ratings_all_movies = pd.DataFrame(columns=['movieId', 'rating'])\n",
    "    user_rating = adjusted_ratings[adjusted_ratings['userId']==userID]\n",
    "\n",
    "    # calculate the ratings for all movies that the user hasn't rated\n",
    "    i = 0\n",
    "    for movie in distinct_movies:\n",
    "        user_rating = user_rating[user_rating['movieId']==movie]\n",
    "        if user_rating.shape[0] > 0:\n",
    "            rating_value = user_ratings_all_movies.loc[i, 'rating'] = user_rating.loc[0, movie]\n",
    "        else:\n",
    "            rating_value = user_ratings_all_movies.loc[i, 'rating'] = predict(userID, movie, w_matrix, adjusted_ratings, rating_mean)\n",
    "        user_ratings_all_movies.loc[i] = [movie, rating_value]\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    # select top 10 movies rated by the user\n",
    "    recommendations = user_ratings_all_movies.sort_values(by=['rating'], ascending=False).head(amount)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId   rating\n",
      "29      32  5.28187\n",
      "27      30  5.20938\n",
      "25      28  5.11111\n",
      "64      86  5.03631\n",
      "9       10  4.96927\n",
      "48      61  4.86426\n",
      "37      43  4.74138\n",
      "24      26  4.61111\n",
      "51      65  4.55653\n",
      "4        5   4.5119\n"
     ]
    }
   ],
   "source": [
    "# get a recommendation list for a given user\n",
    "recommended_movies = recommend(2, w_matrix, adjusted_ratings, rating_mean)\n",
    "print(recommended_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "item-based-collaborative-filtering.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
